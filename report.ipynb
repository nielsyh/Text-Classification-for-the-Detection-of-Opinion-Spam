{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qxGLmKblyJdh"
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "r15WoLfBjxQC",
    "outputId": "0ee876cb-b5ca-4e16-8483-d4b566021ee0"
   },
   "outputs": [],
   "source": [
    "path_neg_true = './database/spam/negative_polarity/truthful_from_Web'\n",
    "path_neg_false = './database/spam/negative_polarity/deceptive_from_MTurk'\n",
    "\n",
    "path_pos_true = './database/spam/positive_polarity/truthful_from_TripAdvisor'\n",
    "path_pos_false = './database/spam/positive_polarity/deceptive_from_MTurk'\n",
    "  \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ngrams\n",
    "import string\n",
    "\n",
    "def read_range(data,a,b,n, label):\n",
    "    res = []\n",
    "    for i in range(a,b):\n",
    "        folder = 'fold'+ str(i)\n",
    "        for file in os.listdir(data + \"/\" + folder):\n",
    "             with open(data + '/' + folder + '/' + file, 'r') as content_file:\n",
    "                content = content_file.read()\n",
    "                res.append(content)\n",
    "    return res\n",
    "\n",
    "def read_dir(data,n, label):\n",
    "  return read_range(data,1,5,n,label),read_range(data,5,6,n,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "scores = ['accuracy']\n",
    "n=1\n",
    "train_neg_true,test_neg_true = read_dir(path_neg_true,n, 'positive')\n",
    "train_neg_false,test_neg_false = read_dir(path_neg_false,n,'negative')\n",
    "\n",
    "dfTrue = pd.DataFrame(train_neg_true)\n",
    "dfTrue['y'] = 1\n",
    "\n",
    "dfFalse = pd.DataFrame(train_neg_false)\n",
    "dfFalse['y'] = 0\n",
    "\n",
    "\n",
    "dfTestTrue = pd.DataFrame(test_neg_true)\n",
    "dfTestTrue['y']=1\n",
    "\n",
    "dfTestFalse = pd.DataFrame(test_neg_false)\n",
    "dfTestFalse['y'] = 0\n",
    "\n",
    "frames = [dfTrue,dfFalse]\n",
    "test_frames = [dfTestTrue,dfTestFalse]\n",
    "\n",
    "df = pd.concat(frames)\n",
    "test_df = pd.concat(test_frames)\n",
    "\n",
    "#Naive Bayes classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clfMNB = Pipeline([ ('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clfLR = Pipeline([ ('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "text_clfCT = Pipeline([ ('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', tree.DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "text_clfRF = Pipeline([ ('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', ExtraTreesClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(text_clf,parameters):\n",
    "    pipe = text_clf.fit(df[0],df['y'])  \n",
    "    predicted = pipe.predict(test_df[0])\n",
    "    gs_clf = GridSearchCV(text_clf, parameters, cv=5)\n",
    "    gs_clf = gs_clf.fit(df[0],df['y'])\n",
    "    predicted = gs_clf.predict(test_df[0])\n",
    "    print(metrics.classification_report(test_df['y'], predicted))\n",
    "    #print(gs_clf.best_score_)\n",
    "    #print(gs_clf.best_estimator_)\n",
    "    \n",
    "    return gs_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_MNB = {\n",
    "               'vect__ngram_range': [(1, 1), (2, 2)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "\n",
    "parameters_DT = {\n",
    "               'vect__ngram_range': [(1, 1), (2, 2)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "}\n",
    "\n",
    "parameters_LR = {\n",
    "               'vect__ngram_range': [(1, 1), (2, 2)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "                'clf__C': [1,0.1,0.001,0.0001],\n",
    "}\n",
    "\n",
    "parameters_RF = {\n",
    "               'vect__ngram_range': [(1, 1), (2, 2)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'clf__n_estimators' : [100, 200, 300],\n",
    "               'clf__max_depth' : [2,3,4,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Naive Bayes--------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.88      0.89        80\n",
      "          1       0.88      0.90      0.89        80\n",
      "\n",
      "avg / total       0.89      0.89      0.89       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-------Naive Bayes--------')\n",
    "mnb = run_pipeline(text_clfMNB,parameters_MNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--------Dec. Trees------')\n",
    "best_tree = run_pipeline(text_clfCT,parameters_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Random forests------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.75      0.72        80\n",
      "          1       0.73      0.68      0.70        80\n",
      "\n",
      "avg / total       0.71      0.71      0.71       160\n",
      "\n",
      "[ 55 298  29 158 220 234 153 304 219  73 226  90 107 173 210  20 101 270\n",
      "  18  25 124 200 115 273 314  52 241  93 277  59 169 159 309 188 126   7\n",
      " 172  37 303  89 207   3  16  68 235 192  92 162 269 199 125 177  94  53\n",
      " 105  28 225 120 217  84 271   9 266  61  60 157 223  48 221  13 198  22\n",
      "  91 211 131 154  47 259 242  79  33  23 248 260 305 295   8 267  14  19\n",
      " 247 261 174  17 194 134 249 204 236 136  38  71 163 312 112 265 127  76\n",
      "  57 246 296 254 168 108 213 250  30 190 287 166 251  10 147 193 231 212\n",
      " 208  11 318 268 245  63 187 149 209  62 161 132 313  97 145  45 275 144\n",
      "   2  34 257 222 281 116 278  95 106 306 272 129  56  50  27 150 262   4\n",
      " 151 215  78 297 244 233 299  83 276 317 185 284 176  70  74 291 135 156\n",
      "  67  58 205  49   5  65  42 300  75  31 202 155 111 117 182 189 230  66\n",
      " 227 319 253  26 110  41 118 165 240  40 170 316 152 139 197  81 286 289\n",
      " 288  86  15 256 228  36  85 123  32 133  21 201 307 203  88 224 122 142\n",
      " 114 102 315 184 229  54 104 232  69 255 178 183 100  72 310 121  51 119\n",
      " 274 280  46 191 292 160 113 302 109 214  98 239 264   6 130 294   0 140\n",
      " 137  24  12 238  35 258 216 301  87 141 282 279 171  44 103 195 243 290\n",
      " 143 164 138  80 128 311 175 218 252  39 206 308  43 148 186 263 167 180\n",
      " 179 181  77  82 283   1 146  99 285 293  64  96 237 196]\n",
      "[0.001018318965517242, 0.000919117647058824, 0.001465516088826745, 0.0025607191396933974, 0.0014178921568627448, 0.0012969802040998961, 0.001024260603956629, 0.002701403670868226, 0.0018195554857247797, 0.002158575814395588, 0.001618003759829141, 0.001571668866527736, 0.0010065351315351333, 0.002008843605820506, 0.001812176950408663, 0.001152777777777778, 0.0025059777381360917, 0.0017985259291888813, 0.0037968450520937938, 0.0018102469445220898, 0.004060182851964527, 0.001131273674242424, 0.0019922770374916, 0.0018654818744979005, 0.0010074626865671653, 0.0036134290513144874, 0.001223473084886129, 0.0014221030171041957, 0.0022977751035658813, 0.009141665748795404, 0.0016392914666542705, 0.0012736362457691883, 0.001139404532304724, 0.0018708143465545495, 0.0014560755336617414, 0.0010061276965204027, 0.0011468763426053324, 0.0026279875026005073, 0.0017499732864046276, 0.0009451220697052603, 0.0011981582959036225, 0.0012187500000000006, 0.001286585201258128, 0.0009417613636363636, 0.00099243485272897, 0.0014793944787979793, 0.001055059523809524, 0.0018873109302788946, 0.002067684393088188, 0.0013065186073205667, 0.0014303946268813092, 0.0010573414556026366, 0.0030884888076972684, 0.0023087450098955723, 0.0010818893078817448, 0.017220686328165605, 0.0014311969711123512, 0.0017178819867865506, 0.0013151952214452204, 0.002830826317477146, 0.0020961197696427827, 0.002117484793669721, 0.001511977905857862, 0.0015499566629396915, 0.0009037366840675649, 0.0012875327875915212, 0.0012383060772691533, 0.0013270406363084107, 0.0024812802262671302, 0.0010792646205730237, 0.001343847720370431, 0.0017488789209682749, 0.0010674048446137742, 0.004894862626841473, 0.0013415046104053431, 0.0012842047895488473, 0.0017237475264145173, 0.0009284274193548392, 0.0014085206660585303, 0.0018708726278806383, 0.0009687499999999998, 0.0011706192358366262, 0.0009241791474654381, 0.0013815575105897684, 0.0021942347956630283, 0.001146602257924445, 0.0011659278959810864, 0.000997102914740628, 0.0011147917969564322, 0.0026091824815384287, 0.00456258416149608, 0.001983720635973567, 0.002432407253802023, 0.0028958526086152554, 0.002312559507184752, 0.00144592463476091, 0.0009029847315445228, 0.0014904306220095704, 0.0010279402709359605, 0.0009121621621621622, 0.0010677609427609419, 0.00400650402388103, 0.0010937279588999818, 0.000988840736099507, 0.001080440779550686, 0.0022978290759509976, 0.001440798967114756, 0.004493313832034001, 0.001667539230917732, 0.0010326787377347938, 0.0012201603133249756, 0.0012565576464483804, 0.0017421456987005758, 0.0010346283783783726, 0.001097244060097834, 0.0033294476485463977, 0.001451556446883978, 0.0012539722308830526, 0.0012173363095238099, 0.0010563380281690105, 0.0022420112781954887, 0.0010624999999999999, 0.0011036234611042418, 0.0011431691851950458, 0.003538440973600498, 0.002336085792292427, 0.002704749228833506, 0.0017263613999935214, 0.0009656566491084029, 0.0014313990655585491, 0.0010185368084397566, 0.0019564263935179355, 0.0015077057855590495, 0.0011314837072649575, 0.0017868716931216909, 0.0013341932457786119, 0.001761735429831266, 0.0010104166666666668, 0.0009690425315425306, 0.00118365008095184, 0.0010174946828743643, 0.0009955357142857136, 0.0011021774687134723, 0.0009818548387096775, 0.001467771584440228, 0.0014832019156346752, 0.0009153669043374935, 0.001604272438141923, 0.0009410421380090499, 0.001523851934744161, 0.0014198648582059473, 0.0014112872219711708, 0.001186161819039969, 0.00537835605820432, 0.0019186043196496982, 0.001263909916810552, 0.0013278388278388285, 0.0020734704612552376, 0.008553864467161627, 0.0027982471139533665, 0.0010399159663865552, 0.0015111370889848577, 0.0024226849934839176, 0.0017455975749345806, 0.0009754497101619423, 0.0012141484641484649, 0.0016216238771376388, 0.0009381398502383391, 0.001673244972596613, 0.002830701726055709, 0.0011979166666666666, 0.0009930555555555565, 0.002660682554034419, 0.0042242075143361394, 0.0017985944997897262, 0.0009464997721576661, 0.0013490489130434783, 0.0023298619536328653, 0.0010756118881118874, 0.0009340010054496577, 0.0009340118032552238, 0.0009300595238095238, 0.0012516874572795638, 0.001067936841238472, 0.0010839429771059236, 0.0013518943104774785, 0.0009394517770876468, 0.001534486808876431, 0.0027166824255761253, 0.0012485421787291995, 0.001633832986511557, 0.0010506220348811461, 0.0024359252018004867, 0.0015920101995823368, 0.0017912867068338497, 0.0009857290762013428, 0.0009005145797598635, 0.0011823635114423115, 0.0020007430370719537, 0.0023564159864942523, 0.003486676270992764, 0.001129726890756302, 0.0012661998903532108, 0.0011179341491841493, 0.0017750660825736956, 0.0013077859640359631, 0.0009449110671936767, 0.0025802777694202694, 0.0015762843697460422, 0.001523357907744319, 0.00414915524688055, 0.0019669697368102502, 0.0015818089416079696, 0.0016532761116637284, 0.0010317719561140609, 0.001410291481022778, 0.0010022945348352097, 0.002207866287676468, 0.0009461777113368263, 0.005023927384262073, 0.006795099905433611, 0.002020403418759072, 0.001455176767676768, 0.002067715243992333, 0.0011041971082059675, 0.002270437895437895, 0.004591881806728449, 0.001235006435006434, 0.001147289396089306, 0.0010829173723343423, 0.0012440186984687802, 0.0015857015175835374, 0.0010798188356782108, 0.0013867092390785715, 0.006784791251370793, 0.002448798513314647, 0.001764817920175093, 0.0009006265748308446, 0.0010062956700615012, 0.0010252282701677462, 0.0012135851321350222, 0.002961824430450117, 0.0018829880267356533, 0.0009854068310310667, 0.001387615983893557, 0.0015502557201570368, 0.0017156100440112467, 0.0017992901999839312, 0.0018584289247582729, 0.0017845280189660827, 0.0016405348124098127, 0.001618685501135718, 0.0009459854966321563, 0.001225432900432899, 0.0016766768588623575, 0.0010784556878306879, 0.0011484375000000034, 0.0014555393479929071, 0.001003959965318293, 0.0018860040909885766, 0.0018483108721391917, 0.0017987782306978736, 0.0014182810888930726, 0.0009393939393939395, 0.0010247950242264975, 0.0017327924590888986, 0.0021575648683274185, 0.0018139869907636483, 0.0015603202282815471, 0.002372198135878973, 0.0038569541059249824, 0.0021865552687033536, 0.0014383812067553286, 0.003107605625385798, 0.0010557272588522602, 0.001473662153217451, 0.001366403000594178, 0.0028924675043357365, 0.001448180158527863, 0.0009931941526610648, 0.0010550728654519733, 0.001454957779538037, 0.0009942500157114223, 0.0009236587757388999, 0.0013516081892791614, 0.0009116504721124283, 0.001168869872817241, 0.0016220181134654825, 0.0011659482758620686, 0.001167363221884497, 0.000984291982099441, 0.0013348877304824953, 0.0010485227874933761, 0.0009061418310834183, 0.001018363303870773, 0.0018249294353874248, 0.001711626082352848, 0.0013979535209828358, 0.010526720162149108, 0.0013822733918128667, 0.0012845360958194977, 0.0009994252873563223, 0.0010339285714285708, 0.0026201044442167114, 0.005070847184799716, 0.0018389771777686554, 0.0014391216760676884, 0.001125103976868747, 0.0009418142621267616, 0.002740866841766628, 0.0010630252100840328, 0.0009537784299339751, 0.0017424640960441947, 0.0014921172080381625, 0.0031065451538180738, 0.0010922960445986754, 0.0011970165641162808, 0.001364880952380953, 0.0015669192519042884, 0.001233277863116572]\n"
     ]
    }
   ],
   "source": [
    "print('-------Random forests------')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#best_forest = run_pipeline(text_clfRF,parameters_RF)\n",
    "\n",
    "best_forest = run_pipeline(text_clfRF,{})\n",
    "forest = best_forest.steps[len(best_forest.steps)-1][1]\n",
    "\n",
    "importante = forest.feature_importances_\n",
    "importances = [x for x in importante if x > 0.0009]\n",
    "indices = np.argsort(importances)[::-1]\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "print(indices)\n",
    "print(importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--------Logistic regression-------')\n",
    "run_pipeline(text_clfLR, parameters_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "report.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
