{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qxGLmKblyJdh"
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "r15WoLfBjxQC",
    "outputId": "0ee876cb-b5ca-4e16-8483-d4b566021ee0"
   },
   "outputs": [],
   "source": [
    "path_neg_true = './database/spam/negative_polarity/truthful_from_Web'\n",
    "path_neg_false = './database/spam/negative_polarity/deceptive_from_MTurk'\n",
    "\n",
    "path_pos_true = './database/spam/positive_polarity/truthful_from_TripAdvisor'\n",
    "path_pos_false = './database/spam/positive_polarity/deceptive_from_MTurk'\n",
    "  \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ngrams\n",
    "import string\n",
    "\n",
    "def read_range(data,a,b,n, label):\n",
    "    res = []\n",
    "    for i in range(a,b):\n",
    "        folder = 'fold'+ str(i)\n",
    "        for file in os.listdir(data + \"/\" + folder):\n",
    "             with open(data + '/' + folder + '/' + file, 'r') as content_file:\n",
    "                content = content_file.read()\n",
    "                res.append(content)\n",
    "    return res\n",
    "\n",
    "def read_dir(data,n, label):\n",
    "  return read_range(data,1,5,n,label),read_range(data,5,6,n,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "scores = ['accuracy']\n",
    "n=1\n",
    "train_neg_true,test_neg_true = read_dir(path_neg_true,n, 'positive')\n",
    "train_neg_false,test_neg_false = read_dir(path_neg_false,n,'negative')\n",
    "\n",
    "dfTrue = pd.DataFrame(train_neg_true)\n",
    "dfTrue['y'] = 1\n",
    "\n",
    "dfFalse = pd.DataFrame(train_neg_false)\n",
    "dfFalse['y'] = 0\n",
    "\n",
    "\n",
    "dfTestTrue = pd.DataFrame(test_neg_true)\n",
    "dfTestTrue['y']=1\n",
    "\n",
    "dfTestFalse = pd.DataFrame(test_neg_false)\n",
    "dfTestFalse['y'] = 0\n",
    "\n",
    "frames = [dfTrue,dfFalse]\n",
    "test_frames = [dfTestTrue,dfTestFalse]\n",
    "\n",
    "df = pd.concat(frames)\n",
    "test_df = pd.concat(test_frames)\n",
    "\n",
    "#Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clfMNB = Pipeline([ ('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clfLR = Pipeline([ ('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "text_clfCT = Pipeline([ ('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                     # ('clf', tree.DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "text_clfRF = Pipeline([ ('vect', CountVectorizer(max_features = 'sqrt')),\n",
    "                      ('tfidf', TfidfTransformer(max_features = 'sqrt')),\n",
    "                      ('clf', ExtraTreesClassifier(max_features = 'sqrt'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def run_pipeline(text_clf,parameters):\n",
    "    pipe = text_clf.fit(df[0],df['y'])  \n",
    "    predicted = pipe.predict(test_df[0])\n",
    "    gs_clf = GridSearchCV(text_clf, parameters, cv=5)\n",
    "    gs_clf = gs_clf.fit(df[0],df['y'])\n",
    "    predicted = gs_clf.predict(test_df[0])\n",
    "    print(metrics.classification_report(test_df['y'], predicted))\n",
    "    print(confusion_matrix(test_df['y'], predicted))\n",
    "    print(gs_clf.best_params_)\n",
    "    return gs_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi = True\n",
    "\n",
    "arr = (1,1)\n",
    "\n",
    "if bi:\n",
    "    arr = (2,2)\n",
    "\n",
    "parameters_MNB = {\n",
    "           'vect__ngram_range': [arr],\n",
    "           'tfidf__use_idf': (True, False),\n",
    "           'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "\n",
    "parameters_DT = {\n",
    "               'vect__ngram_range': [arr],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'clf__max_depth': [999999]\n",
    "}\n",
    "\n",
    "parameters_LR = {\n",
    "               'vect__ngram_range': [arr],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "                'clf__C': [1,0.1,0.001,0.0001],\n",
    "}\n",
    "\n",
    "parameters_RF = {\n",
    "               'vect__ngram_range': [arr],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'clf__n_estimators' : [100, 200, 300]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('--------Dec. Trees------')\n",
    "best_tree = run_pipeline(text_clfCT,parameters_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('-------Random forests------')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "best_forest = run_pipeline(text_clfRF,parameters_RF)\n",
    "forest = best_forest.steps[len(best_forest.steps)-1][1]\n",
    "\n",
    "importante = forest.feature_importances_\n",
    "importances = [x for x in importante if x > 0.001]\n",
    "indices = np.argsort(importances)[::-1]\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "print(indices)\n",
    "print(importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--------Logistic regression-------')\n",
    "run_pipeline(text_clfLR, parameters_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--------Naive bayes-------')\n",
    "run_pipeline(text_clfMNB, parameters_MNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bar(popularity_data,plot_name):\n",
    "  plt.figure(figsize=(15,12))\n",
    "  # sort in-place from highest to lowest\n",
    "  popularity_data.sort(key=lambda x: x[1], reverse=True) \n",
    "\n",
    "  # save the names and their respective scores separately\n",
    "  # reverse the tuples to go from most frequent to least frequent \n",
    "  data,score = zip(*popularity_data)\n",
    "  x_pos = np.arange(len(data))\n",
    "  \n",
    "  #space bars apart\n",
    "  for j in range(len(x_pos)):\n",
    "    x_pos[j]=x_pos[j]+j\n",
    "    \n",
    "  plt.bar(x_pos, score,align='center')\n",
    "  #plt.tick_params(axis='x', which='major', pad=15)\n",
    "    \n",
    "  plt.xticks(x_pos, data) \n",
    "\n",
    "  plt.ylabel(plot_name)\n",
    "  \n",
    "  plt.show()\n",
    "\n",
    "print('-----PLOTING----------')\n",
    "t = ['|Naive Bayes|',\n",
    "     '|Logistic regression|',\n",
    "    '|Class. Tree|',\n",
    "    '|Rand. Forest|',\n",
    "]\n",
    "data = [0.89,0.86,0.63,0.82]\n",
    "bar(list(zip(t,data)),'Average precision unigrams')\n",
    "\n",
    "data = [0.79,0.62,0.84,0.81]\n",
    "bar(list(zip(t,data)),'Average precision bigrams')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "report.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
