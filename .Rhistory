#predictions <-tree.classify(test_data, tree)
measurements(test_labels, predictions)
getConfusionMatrix(train_labels, pr)
}
eclipse()
#run test on eclipse dataset
eclipse <- function() {
#fake data input
train_data <- read.csv('C://dm//eclipse-metrics-packages-2.0.csv', header = TRUE, sep = ";")
test_data <- read.csv('C://dm//eclipse-metrics-packages-3.0.csv', header = TRUE, sep = ";")
v <- 0
v[[1]] = 1
v[[2]] = 2
train_data <- clean_csv(train_data, v)
test_data <- clean_csv(test_data, v)
train_labels <- train_data$post
train_labels <- as.numeric(train_data$post > 0)
train_data$post = NULL
test_labels <- as.numeric(test_data$post > 0)
test_data$post = NULL
trees <- tree.grow.bag(train_data, train_labels, nmin = 15, minleaf = 5, nfeat = 41, m = 1)
predictions <- tree.classify.bag(test_data, trees)
#tree <- tree.grow(train_data, train_labels, nmin = 15, minleaf = 5, nfeat = 41)
#predictions <-tree.classify(test_data, tree)
measurements(test_labels, predictions)
getConfusionMatrix(train_labels, pr)
}
getConfusionMatrix <- function(true_data, train_data) {
u <- union(train_data, true_data)
t <- table(factor(train_data, u), factor(true_data, u))
matrix <- confusionMatrix(t)
return(matrix)
}
eclipse()
#run test on eclipse dataset
eclipse <- function() {
#fake data input
train_data <- read.csv('C://dm//eclipse-metrics-packages-2.0.csv', header = TRUE, sep = ";")
test_data <- read.csv('C://dm//eclipse-metrics-packages-3.0.csv', header = TRUE, sep = ";")
v <- 0
v[[1]] = 1
v[[2]] = 2
train_data <- clean_csv(train_data, v)
test_data <- clean_csv(test_data, v)
train_labels <- train_data$post
train_labels <- as.numeric(train_data$post > 0)
train_data$post = NULL
test_labels <- as.numeric(test_data$post > 0)
test_data$post = NULL
trees <- tree.grow.bag(train_data, train_labels, nmin = 15, minleaf = 5, nfeat = 41, m = 1)
predictions <- tree.classify.bag(test_data, trees)
#tree <- tree.grow(train_data, train_labels, nmin = 15, minleaf = 5, nfeat = 41)
#predictions <-tree.classify(test_data, tree)
measurements(test_labels, predictions)
getConfusionMatrix(test_labels, predictions)
}
eclipse()
#run test on eclipse dataset
eclipse <- function() {
#fake data input
train_data <- read.csv('C://dm//eclipse-metrics-packages-2.0.csv', header = TRUE, sep = ";")
test_data <- read.csv('C://dm//eclipse-metrics-packages-3.0.csv', header = TRUE, sep = ";")
v <- 0
v[[1]] = 1
v[[2]] = 2
train_data <- clean_csv(train_data, v)
test_data <- clean_csv(test_data, v)
train_labels <- train_data$post
train_labels <- as.numeric(train_data$post > 0)
train_data$post = NULL
test_labels <- as.numeric(test_data$post > 0)
test_data$post = NULL
trees <- tree.grow.bag(train_data, train_labels, nmin = 15, minleaf = 5, nfeat = 41, m = 100)
predictions <- tree.classify.bag(test_data, trees)
#tree <- tree.grow(train_data, train_labels, nmin = 15, minleaf = 5, nfeat = 41)
#predictions <-tree.classify(test_data, tree)
measurements(test_labels, predictions)
getConfusionMatrix(test_labels, predictions)
}
eclipse()
#run test on eclipse dataset
eclipse <- function() {
#fake data input
train_data <- read.csv('C://dm//eclipse-metrics-packages-2.0.csv', header = TRUE, sep = ";")
test_data <- read.csv('C://dm//eclipse-metrics-packages-3.0.csv', header = TRUE, sep = ";")
v <- 0
v[[1]] = 1
v[[2]] = 2
train_data <- clean_csv(train_data, v)
test_data <- clean_csv(test_data, v)
train_labels <- train_data$post
train_labels <- as.numeric(train_data$post > 0)
train_data$post = NULL
test_labels <- as.numeric(test_data$post > 0)
test_data$post = NULL
trees <- tree.grow.bag(train_data, train_labels, nmin = 15, minleaf = 5, nfeat = 6, m = 100)
predictions <- tree.classify.bag(test_data, trees)
#tree <- tree.grow(train_data, train_labels, nmin = 15, minleaf = 5, nfeat = 41)
#predictions <-tree.classify(test_data, tree)
measurements(test_labels, predictions)
getConfusionMatrix(test_labels, predictions)
}
eclipse()
library(tm)
if (!require("rpart.plot")) {
install.packages("rpart.plot", dependencies = TRUE, quiet = TRUE)
library("rpart.plot", quietly = TRUE)
}
if (!require("glmnet")) {
install.packages("glmnet", dependencies = TRUE, quiet = TRUE)
library(glmnet, quietly = TRUE)
}
if (!require("randomForest")) {
install.packages("randomForest", dependencies = TRUE, quiet = TRUE)
library(randomForest, quietly = TRUE)
}
#
#
train.mnb <- function (dtm=train.dtm,labels=c()) {
call <- match.call()
V <- ncol(dtm)
N <- nrow(dtm)
prior <- table(labels)/N
labelnames <- names(prior)
nclass <- length(prior)
cond.probs <- matrix(nrow=V , ncol=nclass)
dimnames(cond.probs)[[1]] <- dimnames(dtm)[[2]]
dimnames(cond.probs)[[2]] <- labelnames
index <- list(length=nclass)
for (j in 1:nclass){
index[[j]] <- labels == labelnames[j]
}
for (i in 1:V) {
for (j in 1:nclass){
cond.probs[i,j] <- (sum(dtm[index[[j]],i])+1)/(sum(dtm[index[[j]],])+V)
}
}
list(call=call,prior=prior,cond.probs=cond.probs)
}
#
predict.mnb <- function (model=model,dtm=dtm) {
classlabels <- dimnames(model$cond.probs)[[2]]
logprobs <- dtm %*% log(model$cond.probs)
N <- nrow(dtm)
nclass <- ncol(model$cond.probs)
logprobs <- logprobs + matrix(nrow=N, ncol=nclass, log(model$prior), byrow=T)
classlabels[max.col(logprobs)]
}
# Reads a confusion matrix generated with table() and reports quality measures
# Inputs:
# =======
# t: The input confusion matrix
interpret.cf <- function(t = c()) {
print ("Confusion Matrix")
print (t)
acc <- (t[1,1] + t[2,2]) / sum(t)
print (paste("Accuracy: ", acc, sep = ''))
mis.class.rate <- (t[1,2] + t[2,1]) / sum(t)
print (paste("Misclassification Rate: ", mis.class.rate, sep = ''))
tp.rate <- t[2,2] / (t[2,1] + t[2,2])
print (paste("True Positive Rate: ", tp.rate, sep = ''))
sp <- t[1,1] / (t[1,1] + t[1,2])
print (paste("Specificity: ", sp, sep = ''))
pr <- t[2,2] / (t[1,2] + t[2,2])
print (paste("Precision: ", pr, sep = ''))
}
#
#
read.train.from.directory <- function(dir = "") {
d <- paste(dir, "fold", 1, "/",sep = '')
corp <- VCorpus(DirSource(d, encoding="UTF-8"))
for (i in 2:4) {
d <- paste(dir, "fold", i, "/", sep = '')
corp <- c(corp, VCorpus(DirSource(d, encoding="UTF-8")))
}
return (corp)
}
#
#
preprocess <- function(corpus) {
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, content_transformer(tolower))
return (corpus)
}
setwd('/Users/Niels/Desktop/Practicum_2')
neg.dec.all <- read.train.from.directory(dir = "database/negative_polarity/deceptive_from_MTurk/")
reviews.neg.dec.test <- VCorpus(DirSource("database/negative_polarity/deceptive_from_MTurk/fold5/", encoding="UTF-8"))
neg.truth.all <- read.train.from.directory(dir = "database/negative_polarity/truthful_from_Web/")
reviews.neg.truth.test <- VCorpus(DirSource("database/negative_polarity/truthful_from_Web/fold5/", encoding="UTF-8"))
reviews.all      <- c(neg.dec.all, neg.truth.all)
reviews.all.test <- c(reviews.neg.dec.test, reviews.neg.truth.test)
reviews.all.test <- preprocess(reviews.all.test)
labels.test <- c(rep(0,80),rep(1,80))
reviews.all <- preprocess(reviews.all)
reviews.neg.dec.test <- preprocess(reviews.neg.dec.test)
labels <- c(rep(0,320), rep(1,320))
index.neg <- sample(320,100)
index.pos <- 320+sample(320,100)
index.train <- c(index.neg, index.pos)
train.dtm <- DocumentTermMatrix(reviews.all[index.train])
train.dtm.verysparse <- train.dtm
train.dtm.sparse <- removeSparseTerms(train.dtm, 0.95)
train.dtm.lessparse <- removeSparseTerms(train.dtm, 0.6)
logisticRegNormal <- function() {
###################################
# logistic regression with lasso penalty
reviews.glmnet <- cv.glmnet(as.matrix(train.dtm), labels[index.train], family="binomial",type.measure="class")
plot(reviews.glmnet)
coef(reviews.glmnet, s="lambda.1se")
reviews.logreg.pred <- predict(reviews.glmnet,
newx=as.matrix(test.dtm), s="lambda.1se", type="class")
# show confusion matrix
lr <- table(reviews.logreg.pred, labels[-index.train])
interpret.cf(lr)
}
logisticRegNormal()
logisticRegNormal <- function() {
###################################
# logistic regression with lasso penalty
test.dtm <- DocumentTermMatrix(reviews.all[-index.train],
list(dictionary=dimnames(train.dtm.sparse)[[2]]))
reviews.glmnet <- cv.glmnet(as.matrix(train.dtm), labels[index.train], family="binomial",type.measure="class")
plot(reviews.glmnet)
coef(reviews.glmnet, s="lambda.1se")
reviews.logreg.pred <- predict(reviews.glmnet,
newx=as.matrix(test.dtm), s="lambda.1se", type="class")
# show confusion matrix
lr <- table(reviews.logreg.pred, labels[-index.train])
interpret.cf(lr)
}
logisticRegNormal()
logisticRegNormal <- function() {
###################################
# logistic regression with lasso penalty
test.dtm <- DocumentTermMatrix(reviews.all[-index.train],
list(dictionary=dimnames(train.dtm)[[2]]))
reviews.glmnet <- cv.glmnet(as.matrix(train.dtm), labels[index.train], family="binomial",type.measure="class")
plot(reviews.glmnet)
coef(reviews.glmnet, s="lambda.1se")
reviews.logreg.pred <- predict(reviews.glmnet,
newx=as.matrix(test.dtm), s="lambda.1se", type="class")
# show confusion matrix
lr <- table(reviews.logreg.pred, labels[-index.train])
interpret.cf(lr)
}
logisticRegNormal()
logisticRegBi <- function() {
###################################
# logistic regression with lasso penalty
# extract bigrams
train.dtm2 <- DocumentTermMatrix(reviews.all[index.train],
control = list(tokenize = BigramTokenizer))
train.dtm2 <- removeSparseTerms(train.dtm2,0.99)
train.dat1 <- as.matrix(train.dtm)
train.dat2 <- as.matrix(train.dtm2)
train.dat <- cbind(train.dat1,train.dat2)
#using training dic
test3.dtm <- DocumentTermMatrix(reviews.all[-index.train],
list(dictionary=dimnames(train.dat)[[2]]))
#convert to ordinary matrix
test3.dat <- as.matrix(test3.dtm)
# get columns in the same order as on the training set
test3.dat <- test3.dat[,dimnames(train.dat)[[2]]]
# make predictions using lambda.1se
reviews.logreg3.pred <- predict(reviews3.glmnet,newx=test3.dat,
s="lambda.1se",type="class")
# show confusion matrix
lr <- table(reviews.logreg.pred, labels[-index.train])
interpret.cf(lr)
}
logisticRegBi()
BigramTokenizer <-function(x) unlist(lapply(ngrams(words(x), c(1,2,3)), paste, collapse = " "), use.names = FALSE)
logisticRegBi()
logisticRegBi <- function() {
###################################
# logistic regression with lasso penalty
# extract bigrams
train.dtm2 <- DocumentTermMatrix(reviews.all[index.train],
control = list(tokenize = BigramTokenizer))
train.dtm2 <- removeSparseTerms(train.dtm2,0.99)
train.dat1 <- as.matrix(train.dtm)
train.dat2 <- as.matrix(train.dtm2)
train.dat <- cbind(train.dat1,train.dat2)
#using training dic
test3.dtm <- DocumentTermMatrix(reviews.all[-index.train],
list(dictionary=dimnames(train.dat)[[2]]))
#convert to ordinary matrix
test3.dat <- as.matrix(test3.dtm)
# get columns in the same order as on the training set
test3.dat <- test3.dat[,dimnames(train.dat)[[2]]]
# make predictions using lambda.1se
reviews.logreg3.pred <- predict(reviews3.glmnet,newx=test3.dat,
s="lambda.1se",type="class")
# show confusion matrix
lr <- table(reviews.logreg.pred3, labels[-index.train])
interpret.cf(lr)
}
logisticRegBi()
logisticRegBi <- function() {
###################################
# logistic regression with lasso penalty
# extract bigrams
train.dtm2 <- DocumentTermMatrix(reviews.all[index.train],
control = list(tokenize = BigramTokenizer))
train.dtm2 <- removeSparseTerms(train.dtm2,0.99)
train.dat1 <- as.matrix(train.dtm)
train.dat2 <- as.matrix(train.dtm2)
train.dat <- cbind(train.dat1,train.dat2)
# fit regularized logistic regression model
# use cross-validation to evaluate different lambda values
reviews3.glmnet <- cv.glmnet(train.dat,labels[index.train],
family="binomial",type.measure="class")
# show coefficient estimates for lambda-1se
coef(reviews3.glmnet,s="lambda.1se")
#using training dic
test3.dtm <- DocumentTermMatrix(reviews.all[-index.train],
list(dictionary=dimnames(train.dat)[[2]]))
#convert to ordinary matrix
test3.dat <- as.matrix(test3.dtm)
# get columns in the same order as on the training set
test3.dat <- test3.dat[,dimnames(train.dat)[[2]]]
# make predictions using lambda.1se
reviews.logreg3.pred <- predict(reviews3.glmnet,newx=test3.dat,
s="lambda.1se",type="class")
# show confusion matrix
lr <- table(reviews.logreg.pred3, labels[-index.train])
interpret.cf(lr)
}
logisticRegBi()
logisticRegBi <- function() {
###################################
# logistic regression with lasso penalty
# extract bigrams
train.dtm2 <- DocumentTermMatrix(reviews.all[index.train],
control = list(tokenize = BigramTokenizer))
train.dtm2 <- removeSparseTerms(train.dtm2,0.99)
train.dat1 <- as.matrix(train.dtm)
train.dat2 <- as.matrix(train.dtm2)
train.dat <- cbind(train.dat1,train.dat2)
# fit regularized logistic regression model
# use cross-validation to evaluate different lambda values
reviews3.glmnet <- cv.glmnet(train.dat,labels[index.train],
family="binomial",type.measure="class")
# show coefficient estimates for lambda-1se
coef(reviews3.glmnet,s="lambda.1se")
#using training dic
test3.dtm <- DocumentTermMatrix(reviews.all[-index.train],
list(dictionary=dimnames(train.dat)[[2]]))
#convert to ordinary matrix
test3.dat <- as.matrix(test3.dtm)
# get columns in the same order as on the training set
test3.dat <- test3.dat[,dimnames(train.dat)[[2]]]
# make predictions using lambda.1se
reviews.logreg.pred3 <- predict(reviews3.glmnet,newx=test3.dat,
s="lambda.1se",type="class")
# show confusion matrix
lr <- table(reviews.logreg.pred3, labels[-index.train])
interpret.cf(lr)
}
logisticRegBi()
NaiveBayesBi <- function(){
# extract bigrams
train.dtm2 <- DocumentTermMatrix(reviews.all[index.train],
control = list(tokenize = BigramTokenizer))
train.dtm2 <- removeSparseTerms(train.dtm2,0.99)
train.dat1 <- as.matrix(train.dtm)
train.dat2 <- as.matrix(train.dtm2)
train.dat <- cbind(train.dat1,train.dat2)
#using training dic
test3.dtm <- DocumentTermMatrix(reviews.all[-index.train],
list(dictionary=dimnames(train.dat)[[2]]))
#convert to ordinary matrix
test3.dat <- as.matrix(test3.dtm)
# get columns in the same order as on the training set
test3.dat <- test3.dat[,dimnames(train.dat)[[2]]]
reviews.mnb <- train.mnb(as.matrix(train.dat), labels[index.train])
test.dtm <- DocumentTermMatrix(reviews.all[-index.train],
list(dictionary=dimnames(train.dat)[[2]]))
reviews.mnb.pred <- predict.mnb(reviews.mnb, as.matrix(test.dtm))
nb.cm <- table(reviews.mnb.pred, labels[-index.train])
interpret.cf(nb.cm)
}
NaiveBayesBi()
NaiveBayesBi <- function(){
# extract bigrams
train.dtm2 <- DocumentTermMatrix(reviews.all[index.train],
control = list(tokenize = BigramTokenizer))
train.dtm2 <- removeSparseTerms(train.dtm2,0.99)
train.dat1 <- as.matrix(train.dtm)
train.dat2 <- as.matrix(train.dtm2)
train.dat <- cbind(train.dat1,train.dat2)
#using training dic
test3.dtm <- DocumentTermMatrix(reviews.all[-index.train],
list(dictionary=dimnames(train.dat)[[2]]))
#convert to ordinary matrix
test3.dat <- as.matrix(test3.dtm)
# get columns in the same order as on the training set
test3.dat <- test3.dat[,dimnames(train.dat)[[2]]]
reviews.mnb <- train.mnb(as.matrix(train.dat), labels[index.train])
test.dtm <- DocumentTermMatrix(reviews.all[-index.train],
list(dictionary=dimnames(train.dat)[[2]]))
reviews.mnb.pred <- predict.mnb(reviews.mnb, as.matrix(test3.dtm))
nb.cm <- table(reviews.mnb.pred, labels[-index.train])
interpret.cf(nb.cm)
}
NaiveBayesBi()
NaiveBayesBi <- function(){
# extract bigrams
train.dtm2 <- DocumentTermMatrix(reviews.all[index.train],
control = list(tokenize = BigramTokenizer))
train.dtm2 <- removeSparseTerms(train.dtm2,0.99)
train.dat1 <- as.matrix(train.dtm)
train.dat2 <- as.matrix(train.dtm2)
train.dat <- cbind(train.dat1,train.dat2)
reviews.mnb <- train.mnb(as.matrix(train.dat), labels[index.train])
test.dtm <- DocumentTermMatrix(reviews.all[-index.train],
list(dictionary=dimnames(train.dat)[[2]]))
#using training dic
test3.dtm <- DocumentTermMatrix(reviews.all[-index.train],
list(dictionary=dimnames(train.dat)[[2]]))
#convert to ordinary matrix
test3.dat <- as.matrix(test3.dtm)
# get columns in the same order as on the training set
test3.dat <- test3.dat[,dimnames(train.dat)[[2]]]
reviews.mnb.pred <- predict.mnb(reviews.mnb, as.matrix(test3.dtm))
nb.cm <- table(reviews.mnb.pred, labels[-index.train])
interpret.cf(nb.cm)
}
NaiveBayesBi()
NaiveBayesBi <- function(){
# extract bigrams
train.dtm2 <- DocumentTermMatrix(reviews.all[index.train],
control = list(tokenize = BigramTokenizer))
train.dtm2 <- removeSparseTerms(train.dtm2,0.99)
train.dat1 <- as.matrix(train.dtm)
train.dat2 <- as.matrix(train.dtm2)
train.dat <- cbind(train.dat1,train.dat2)
reviews.mnb <- train.mnb(as.matrix(train.dat), labels[index.train])
#using training dic
test3.dtm <- DocumentTermMatrix(reviews.all[-index.train],
list(dictionary=dimnames(train.dat)[[2]]))
#convert to ordinary matrix
test3.dat <- as.matrix(test3.dtm)
# get columns in the same order as on the training set
test3.dat <- test3.dat[,dimnames(train.dat)[[2]]]
reviews.mnb.pred <- predict.mnb(reviews.mnb, as.matrix(test3.dtm))
nb.cm <- table(reviews.mnb.pred, labels[-index.train])
interpret.cf(nb.cm)
}
NaiveBayesBi()
logisticRegBi()
logisticRegBi()
NaiveBayesBi()
reviews.mnb.pred
test3.dat
reviews.mnb
train.dtm2 <- DocumentTermMatrix(reviews.all[index.train],
control = list(tokenize = BigramTokenizer))
train.dtm2 <- removeSparseTerms(train.dtm2,0.99)
train.dat1 <- as.matrix(train.dtm)
train.dat2 <- as.matrix(train.dtm2)
train.dat <- cbind(train.dat1,train.dat2)
reviews.mnb <- train.mnb(as.matrix(train.dat), labels[index.train])
#using training dic
test3.dtm <- DocumentTermMatrix(reviews.all[-index.train],
list(dictionary=dimnames(train.dat)[[2]]))
#convert to ordinary matrix
test3.dat <- as.matrix(test3.dtm)
# get columns in the same order as on the training set
test3.dat <- test3.dat[,dimnames(train.dat)[[2]]]
reviews.mnb.pred <- predict.mnb(reviews.mnb, as.matrix(test3.dtm))
reviews.mnb.pred <- predict.mnb(reviews.mnb, as.matrix(test3.dtm))
reviews.mnb.pred <- predict.mnb(reviews.mnb, as.matrix(test.dtm))
reviews.mnb.pred <- predict.mnb(reviews.mnb, as.matrix(test3.dtm))
reviews.mnb.pred <- predict(reviews.mnb, as.matrix(test3.dtm))
reviews.mnb.pred <- predict.mnb(reviews.mnb, as.matrix(test3.dtm))
train.mnb <- function (dtm,labels)
{
call <- match.call()
V <- ncol(dtm)
N <- nrow(dtm)
prior <- table(labels)/N
labelnames <- names(prior)
nclass <- length(prior)
cond.probs <- matrix(nrow=V,ncol=nclass)
dimnames(cond.probs)[[1]] <- dimnames(dtm)[[2]]
dimnames(cond.probs)[[2]] <- labelnames
index <- list(length=nclass)
for(j in 1:nclass){
index[[j]] <- c(1:N)[labels == labelnames[j]]
}
for(i in 1:V){
for(j in 1:nclass){
cond.probs[i,j] <- (sum(dtm[index[[j]],i])+1)/(sum(dtm[index[[j]],])+V)
}
}
list(call=call,prior=prior,cond.probs=cond.probs)
}
predict.mnb <-
function (model,dtm)
{
classlabels <- dimnames(model$cond.probs)[[2]]
logprobs <- dtm %*% log(model$cond.probs)
N <- nrow(dtm)
nclass <- ncol(model$cond.probs)
logprobs <- logprobs+matrix(nrow=N,ncol=nclass,log(model$prior),byrow=T)
classlabels[max.col(logprobs)]
}
reviews.mnb.pred <- predict.mnb(reviews.mnb, as.matrix(test3.dtm))
